%% ****** Start of file apstemplate.tex ****** %
%%
%%
%%   This file is part of the APS files in the REVTeX 4 distribution.
%%   Version 4.1r of REVTeX, August 2010
%%
%%
%%   Copyright (c) 2001, 2009, 2010 The American Physical Society.
%%
%%   See the REVTeX 4 README file for restrictions and more information.
%%
%
% This is a template for producing manuscripts for use with REVTEX 4.0
% Copy this file to another name and then work on that file.
% That way, you always have this original template file to use.
%
% Group addresses by affiliation; use superscriptaddress for long
% author lists, or if there are many overlapping affiliations.
% For Phys. Rev. appearance, change preprint to twocolumn.
% Choose pra, prb, prc, prd, pre, prl, prstab, prstper, or rmp for journal
%  Add 'draft' option to mark overfull boxes with black boxes
%  Add 'showpacs' option to make PACS codes appear
%  Add 'showkeys' option to make keywords appear
%\documentclass[aps,prl,preprint,groupedaddress]{revtex4-1}
%\documentclass[aps,prl,preprint,superscriptaddress]{revtex4-1}
\documentclass[aps,prl,reprint,groupedaddress]{revtex4-1}

% You should use BibTeX and apsrev.bst for references
% Choosing a journal automatically selects the correct APS
% BibTeX style file (bst file), so only uncomment the line
% below if necessary.
%\bibliographystyle{apsrev4-1}

\begin{document}

% Use the \preprint command to place your local institutional report
% number in the upper righthand corner of the title page in preprint mode.
% Multiple \preprint commands are allowed.
% Use the 'preprintnumbers' class option to override journal defaults
% to display numbers if necessary
%\preprint{}

%Title of paper
\title{Phase Transitions in Networks of Memristive Elements}

% repeat the \author .. \affiliation  etc. as needed
% \email, \thanks, \homepage, \altaffiliation all apply to the current
% author. Explanatory text should go in the []'s, actual e-mail
% address or url should go in the {}'s for \email and \homepage.
% Please use the appropriate macro foreach each type of information

% \affiliation command applies to all authors since the last
% \affiliation command. The \affiliation command should follow the
% other information
% \affiliation can be followed by \email, \homepage, \thanks as well.
\author{Forrest C. Sheldon}
\email[]{fsheldon@ucsd.edu}
%\homepage[]{Your web page}
%\thanks{}
%\altaffiliation{}


\author{Massimiliano Di Ventra}
\email[]{diventra@ucsd.edu}
%\homepage[]{Your web page}
%\thanks{}
%\altaffiliation{}
\affiliation{Department of Physics, University of California San Diego,
La Jolla, California 92093, USA}

%Collaboration name if desired (requires use of superscriptaddress
%option in \documentclass). \noaffiliation is required (may also be
%used with the \author command).
%\collaboration can be followed by \email, \homepage, \thanks as well.
%\collaboration{}
%\noaffiliation

\date{\today}

\begin{abstract}
% insert abstract here
The memory features of memristive elements, analogous to those in biological
synapses have spurred the development of neuromorphic systems based on them.
In turn, this requires a fundamental understanding of the collective
dynamics of networks of memristive elements.  Here, we study an experimentally
inspired model of disordered memristive networks in the limit of a slowly
ramped voltage and show through simulations that these networks undergo a
first-order phase transition in the conductivity for sufficiently high
values of memory as quantified by the memristive ON/OFF ratio. We also
provide a mean-field theory that reproduces many features of the transition
and particularly examine the role of boundary conditions in current- vs.
voltage-controlled networks.
\end{abstract}

% insert suggested PACS numbers in braces on next line
\pacs{}
% insert suggested keywords - APS authors don't need to do this
%\keywords{}

%\maketitle must follow title, authors, abstract, \pacs, and \keywords
\maketitle

% body of paper here - Use proper section commands
% References should be done using the \cite, \ref, and \label commands
%\section{}
% Put \label in argument of \section for cross-referencing
%\section{\label{}}
%\subsection{}
%\subsubsection{}

\section{INTRODUCTION}

While devices and materials that display resistive switching have been known
since the 1960s, interest has surged recently with the realization that their
dynamics can support computation both as logical and memory components.
Initially, much of this interest focused on the memristor, an ideal
resistive switching device characterized by Chua whose resistance depends
only on the past
history of the current.  Recently, the wider class of memristive elements, whose
resistance can depend on other state variables and with more complex
dependencies, has begun to see attention, especially in the field of
neuromorphic computing.  Of particular note is the tendency of some memristive
elements to display a history dependent decay constant, allowing a transition
between a volatile and non-volatile regime of memory.  The resulting dynamics
bear a resemblance to the short-term and long-term potentiation observed in
biological synapses and thought to be of central importance to learning and
plasticity in the brain.  This resemblance has begun to inspire experimental
systems that seek to combine the memory features of biological synapses with
the structural complexity of neural tissue.

Until recently, fabricating structures with a complex, disordered architecture
similar to that seen in the nervous system was an unmet challenge.  By
utilizing a growth process, Gimzewski et al. succeeded in producing a material
that approximates this structure with a high density of inorganic synapses
($\approx 10^9 /cm^2$) in the form of memristive $Ag|Ag_2 S|Ag$ atomic
 switches.  $Ag$ depositing from solution forms complex structures through a
diffusion-limited aggregation-like growth process.  After these have formed
an inteconnected network, exposure to sulfur gas forms insulating junctions
of $Ag_2 S$ throughout, capable of bipolar memristive switching.
It is hoped that through the interplay of the synaptic dynamics and complex
structure, these biomimetic chips might show emergent behaviors useful to
neuromorphic systems or relevant to brain function.

Additionally, memristive elements are being actively researched as medium for
non-von Neumann computers to address the von Neumann Bottleneck
\cite{Backus1978} whereby increases in processor speed are muted by the
necessity of shuttling data and addresses back and forth between the
processor and memory.  In these devices, networks of memristive elements
dynamically organize to seek solutions of computational problems, thereby
performing the computation directly in the memory and avoiding the separation
between logical and memory units.  Understanding
the capabilities of these computers will require an undestanding of memristive
dynamics in networks.

Theoretical investigations of one-dimensional networks have shown the
capability for complex temporal dynamics and scale-invariant properties but
have not clarified if or how collective behaviors might arise.  In
two-dimensions, theoretical work has been limited to simulations of memristor
models in relatively small networks but these have duplicated several features
seen in the experimental systems produced by Gimzewski.  An analytical
description is still lacking and to address this we propose a simplified model
for disordered memristor networks inspired by the experiments of Gimzewski.
Through simulations we show that this model experiences a first order phase
transition in the conductivity in the limit of a slowly ramped voltage for
sufficiently large values of the memristive ON/OFF
ratio.  We find that this behavior is well described by a mean field theory
similar to that of the zero-temperature random-field Ising model (RFIM).
The mean-field theory
demonstrates several regimes of behavior observed in simulations and is
capable of showing bipolar switching (a phase transition from OFF to ON and
ON to OFF).  The dynamics implied by the mean-field theory demonstrate
avalanches similar to those observed in neuronal cultures and these lead
to a distribution of conductance jumps which may be accessible experimentally.

\section{MODEL}

$Ag | Ag_2 S | Ag$ gapless atomic switches consist of an insulating layer
of silver sulfide between two silver electrodes.  As a voltage is
applied, the silver sulfide crystal undergoes a phase transition from
monoclinic acanthite to body centered argentite in which the diffusivity of
silver through the crystal increases dramatically.  Silver ions drift
from anode to cathode and deposit, forming a filament structure that eventually
bridges the insulator \cite{Xu2010}. As the filament grows, the
tunneling gap shrinks and there is an eventual transition from tunneling
to ballistic conductance as the filament completes
\cite{Hasegawa2010, Sun2014}. Competition between the transport induced
filament growth and it's thermal fluctuation induced dissolution allow the
atomic switch to display learning abilities analogous to an organic synapse:
short current pulses through an incomplete filament will change the tunneling
gap, but these changes to the conductivity will be erased over short timescales
by thermal fluctuations, giving a short term memory behavior to the junction.
Longer current pulses will complete the filament, lengthening the timescales
for thermal dissolution and thus displaying a nonvolatile long term memory
\cite{Hasegawa2010, Ohno2011}.

From this we note the following: the insulating OFF phase is
thermodynamically favored
and so devices may be assumed to be initially OFF, the conductance of
individual junctions is not necessarily a linear function of filament length
and may increase sharply across some short range (this seems to be supported
by fluctuations in experimental networks in which the conductance jumps
sharply, indicating similar behavior for junctions within), and that
there is a voltage or current threshold below which thermal fluctuations
dominate and filament
growth will not occur but above which the devices will proceed to a
conducting state.

We now turn to a network of these elements.  We consider a bus bar
architecture
where the upper and lower boundaries of a network are held to the same
voltage or total current as was used in studies of the random resistor network.
Structural disorder in the
network induces a voltage distribution over the elements, concentrating
current near defects. As the voltage is raised, the bond with the largest
current will cross it's threshold first and proceed to it's conducting state.
As this occurs, other bonds currents may be raised above threshold through
two avenues: as a bond becomes more conductive, it draws from the surrounding
network, decreasing currents in parallel but increasing currents in bonds near
its entrance and exit, and the conductivity of a single bond increasing also
increases the conductivity of the network thus draws more current at the
boundaries in a voltage-controlled network. These bonds will then proceed to
their conducting state and the process can repeat.  If the voltage varies
slowly relative to the switching of an individual memristive element, we may
regard it as fixed during this switching process, and if the conductance
function is rapidly varying over some small range of filament growth (as,
we noted above, seems to be true of experimental devices) we can regard the
individual elements as switching discontinuously from
$g_{off}$ to $g_{on}$.

As structural disorder is somewhat difficult to treat analytically we simplify
the role of disorder in our model as follows.  Structural disorder
influences the dynamics through the voltage distribution it induces and so we
turn our attention there.  If we could randomly assign voltages directly
from this distribution, the element with the largest voltage drop in the
network would cross its threshold first as the voltage at the boundaries was
increased.  This is equivalent, however, to
assigning a threshold randomly to elements all held at the same voltage and
allowing the element with the lowest threshold to switch as the voltage is
increased.  As we can regard these two types of disorder as equivalent, and
networks may display disorder in the threshold distribution as well, we absorb
the structural disorder into the threshold distribution and regard the
randomly assigned threshold as representing the combination of many possible
types of disorder in the network.  We also note that this comes at the price
of removing spatial correlations in the voltage distribution induced by the
structural disorder.

We thus propose a model for a disordered memristive lattice consisting of a
regular lattice biased along the upper and lower boundaries.  Elements in
the lattice begin in the thermodynamically favored OFF state with conductance
$g_{off}$ and each is assigned a current threshold $t_i$ from distribution
$p(t)$.  When an element's threshold is crossed, it switches immediately to
it's conducting ON state with conductance $g_{on}$ in a non-volatile manner,
such that reducing the voltage will not cause it to switch back until
it has crossed a negative threshold.  When no elements are
switching, the voltage is raised to cross the smallest threshold of a device
in it's OFF state and subsequent switchings are allowed to occur with the
boundary voltage held fixed.  Atomic switches are also polar elements and
here we have chosen the polarity to coincide with the direction selected by
currents from the boundaries.  This assumption should be the case for
the experimental networks discussed above as their polarity is seemingly
imposed by a formation step.  See Supplemental Material at []
for a discussion of this effect.

\section{SIMULATIONS}

Simulations were carried out for a square lattice at a variety of sizes,
ON/OFF ratios, and threshold distributions $p(t)$.  The network dimensions
were chosen such that the conductivity of the network preceded from $g_{off}$
to $g_{on}$.  To reduce finite size effects, networks were periodic in the
$\hat{x}$ direction and an external voltage was applied along $\hat{y}$. In
Figure FIGURE HERE we have displayed the network conductances as a function of
applied voltage for various values of $g_{on}$ setting $g_{off} = 1$ and for
threshold distibution $p(t) = Uniform(0,1)$.  The displayed networks have
a linear size of $L_x=64$ lattice sites which we found large enough to achieve
regular results over multiple realizations of the disorder. Conductances
have been scaled to lie on the interval $[0,1]$. We note that for small values
of $g_{on}$ the conductance is a smooth function of the voltage.  As $g_{on}$
is increased, a discontinuity forms in the slope which sharpens, appearing
almost continuous until a discontinuous jump appears for large $g_{on}$
indicating a first-order phase transition.  Similar behavior was seen for
a variety of other distributions with the point of transition being
distribution dependent.

Observing the dynamics of a network leading up to a transition, we observe
distinct regimes of behavior similar to those seen in studies of fuse
networks. These have been plotted in Figure FIGURE HERE
where unswitched elements are colored grey and elements that have switched
ON are colored black. Early on, when few elements have switched,
we observe a diffusive regime, when switchings are largely individual and
spatially separated across the lattice FIGURE A.  As the process continues,
small avalanches can be observed and the switching becomes increasingly
localized FIGURE B.  At the transition, a conducting backbone is formed
FIGURE C and the networks proceed to quickly saturate in the conducting state.

The transition observed in this simplified model of a memristive network
matches behavior seen in experimental and theoretical investigations of
memristors where the full time integration of their memristive state is
undertaken.  Experimental networks exhibit a transition with a sharp
threshold from an OFF to ON state as seen in CITE FIGURE GEMZEWSKI and a
similar transition from ON to OFF when the applied voltage is reversed.
This ability for the network to switch coherently and thus act as a large
memristive device was also seen in simulations of small networks, but due to
small sizes and timescales, it is difficult to perceive a sharp transition.
They do, however, connect the transition of the network to the appearance of
a conducting backbone.  Our simplified model thus appears relevant to the
dynamics of actual memristors undergoing their full time evolution.  We now
propose a mean-field theory that captures many features of the transition.

\section{MEAN-FIELD THEORY}

\subsection{Self-Consistency Equation}

In order to treat conductive networks we follow the method of Zapperi et al.
\cite{Zapperi1999} used in analyzing random fuse networks.  In the following,
$\sigma_i$ is the conductance of the $i$th element of the network,
and \(\phi(f) = \frac{1}{N}\sum_i \sigma_i = g_{off} + f (g_{on} - g_{off})\)
is the average conductance of an element where $f$ is the fraction of elements
in the ON state. Central to this method is the approximation of the network
conductance $G(\{\sigma_i\})$ by an effective medium theory giving $G_{eff}(f)$
as a function only of the fraction of devices in the ON state.  This
simplification is possible with the assumption that the conductors are
uniformly mixed throughout the system, however in simulations we have seen
that this is not the case and correlations are present in the switchings of
elements, especially at the transition where a conducting backbone appears.
While the mean-field theory should thus over-estimate the transition voltage,
we will find that it does account for many behaviors seen in simulations and
gives a description of the system dynamics.

Beginning with the power dissipated by the network, this may be written as a
sum over individual elements, or using the network conductance and applied
voltage $V$,
\[P = \sum_i \sigma_i \Delta V_i^2 = G(\{\sigma_i\}) V^2\]
where this equivalence defines the network conductance $G(\{\sigma_i\})$.
Using the effective medium approximation and inserting factors of $\phi(f)$,
we find,
\[P = \sum_i \sigma_i \Delta V_i^2 = \sum_i \sigma_i \frac{G_{eff}(f)V^2}
{\phi(f) N}\]
and thus, at the mean-field level, each element is subjected to a voltage
\[\Delta V_{MF} = \sqrt{\frac{G_{eff}(f)}{\phi(f)}}\frac{V}{\sqrt{N}}
= h(f) v.\]
We recognize $v=V/\sqrt{N}$ as the applied local field.  The function
$h(f)$ determines what fraction of the applied field each element
experiences at the mean field level.  The functions $\phi(f)$, $G_{eff}(f)$,
and $h(f)$ are plotted in Figure FIGURE. We can understand the non-monotonic
form of $h(f)$ as arising from competition between switching elements
concentrating current away from other elements, and the increasing conductance
of the network pulling more current in at the boundaries.  For small $f$, the
average conductance of an element is increasing faster than the network
conductivity, indicating that current is concentrated away from other elements
more quickly than it increases at the boundaries and the mean field voltage
decreases.  For larger $f$, the network conductance begins to increase more
quickly than the average conductance, pulling in current faster than switching
elements can concentrate it, and the mean field voltage increases.  The
increasing regime at large $f$ allows for a phase transition to occur from
OFF to ON and the decreasing portion at low $f$ allows for the possibility
of the reverse transition when the voltage is reversed.  One-dimensional and
current controlled networks do not show this non-monotonic $f$ dependence and
so can only show a transition in one direction.

To determine whether a transition occurs for a particular disorder
distribution, we form a
self consistency equation, ensemble averaging over the number of elements
that have switched for a given mean field voltage. For the transition from
OFF to ON, the fraction that have switched will approach the average fraction
of elements with thresholds below the mean-field voltage,
\begin{equation}\label{selfconsist}
f = \int_0^{h(f) v} p(t) dt.
\end{equation}
Because the applied field enters multiplicatively, the dynamics given by
the mean-field theory depends only on the conductance ratio $g_{on}/g_{off}$
and is independent of the scale of the disorder, either amounting only to
a rescaling of the applied field $v$.  The LHS and
RHS are plotted for several values of the voltage in Figure FIGURE.  For
the chosen distribution and ON/OFF ratio a transition is evident at the
point
\begin{equation}\label{PT_eqn}
1 = p'(h(f)v)h'(f)v \quad 0\le f\le 1.
\end{equation}
If a particular disorder distribution and ON/OFF ratio allows for the
simultaneous solution of \ref{selfconsist} and \ref{PT_eqn}, the mean-field
theory demonstrates a phase transition. We also note that the inflection
of the curves from the RHS gives behavior that looks almost like a continuous
transition, corresponding to the behavior seen in simulations for intermediate
values of $g_{on}$.
A similar analysis can be performed
for switching from ON to OFF. This is included in Supplemental Material
at [].

\subsection{Dynamics}

We now turn to the dynamics of a single network as it approaches the
transition.  As the external voltage is raised, a single memristive element
will cross it's threshold and switch, taking $f\to f + \frac{1}{N}$.
According to the RHS of the self consistency equation \ref{selfconsist},
this will cause
elements with thresholds on the interval $[h(f)v, h(f)v + \frac{h'(f)v}{N}]$
to switch.  The probability of finding $n$ memristors on this interval is
poisson distributed with mean $\mu = p(h(f)v)h'(f)v$. Several elements
switching will lead to a corresponding interval for each. In the large $N$
limit, we can thus treat the avalanches as a branching process with a
poissonian offspring distribution as given above.  As the behavior of a
branching process is characterized by the mean of its offspring distribution,
we can use this to make precise the regimes of behavior noted in simulations.
When $h'(f)<0$ we should see no avalanches, corresponding to the diffusive
regime.  As $f$ increases, for $0<\mu < 1$ we will see avalanches of finite
size, corresponding to a subcritical branching regime.  When $\mu$ reaches 1,
the system reaches a critical branching process, in which the probability of
an infinite avalanche begins to rise from 0. Taking $\mu=1$ with the form of
$\mu$ given above return the same requirement for the transition given by the
self-consistency equation.

In order to make understand how relevant this description of the dynamics is to
experiment, we note that the jumps in conductance of the network should be 
related in a simple way to the avalanche size distribution.  In particular,
an avalanche of $S$ elements, should correspond to a jump of conductance of
$G'(f)\frac{S}{N}$.  The conductance jump distribution should thus have the
same form as the avalanche size distribution. For a Poissonian branching
process, this takes the form of a Borel distibution
(see Supplemental Material at [URL]),
\[p(s) = \frac{(\mu s)^{s-1}}{s!}e^{-\mu s}.\]
While achieving a quantitative agreement with simulation based on this is
difficult because because of the effect of correlations,
as $\mu\to 1$ this distribution takes on a particularly simple form,
\[P(s) \to s^{-3/2}.\]
In order to examine whether this would be accessible in experiments, we
simulated randomly diluted lattices without threshold disorder as the
effect of spatial correlations may modify the behavior.  Avalanches were
binned in the region surrounding the peak in the avalanche size for
various sizes of the networks. The histograms produced are plotted in
figure FIGURE HERE. As the system size increases, the histograms approach
the form predicted by the mean field theory but subject to a finite-size
cutoff.

\section{DISCUSSION}

We have presented a simple model that captures the behavior of a memristive
network in the adiabatic limit.  As the memristive ON/OFF ratio is increased,
the conductivity moves from a smooth function of the applied voltage to
displaying a discontinuous jump indicating a first-order phase transition.
A mean-field theory captures this behavior and describes the dynamics
surrounding the transition well.  We have emphasized that the transition is
due to two effects in the lattice, the switching memristive elements alter the
conductivity of the lattice and thus change the amount of current being drawn
in at the boundaries, and they concentrate current, pulling it away from
elements in parallel with them and increasing it in elements in series.  While
it is expected that the mean-field theory can capture the first of these, it
is perhaps surprising that it captures part of the second.  Competition
between these two effects leads to behavior in two-dimensional 
voltage-controlled networks not seen in one-dimension or current controlled
networks and this behavior, given by the non-monotonic form of $h(f)$ allows
for bipolar transitions.

The mean-field theory also accounts for the dynamics of the model, giving
a 'conductance noise' analogous the Barkhausen noise seen in magnetic systems
displaying hysteresis.  At the transition of the network the avalanche
size distribution approaches a power law.  It is interesting to note that
the exponent matches that seen in neural cultures displaying avalanches which
are also described by a branching process but, as the spiking in neural
networks is quite different from the switching of memristive elements the
analogy is difficult to push too far.  It does however demonstrate that
memristors should be capable of some of the complex dynamics seen in biological
neural networks.

Lastly, an important application of memristive networks such as these is the
fabrication of memristors with dimensions larger than the nanoscale. As
previous work has shown through simulation, networks of memristors will act
as a larger single memristor.  Here we demonstrate that the inclusion of
disorder in these networks still allows for regular memristive switching
through the collective behavior of the elements.  In using such devices to
support massively parallel computation, an important design criteria is the
number of accessible conductance states.  While for a network of two state
devices, the number of network states is $2^N$, only a subset of these are
accessible when the network is controlled from the boundary. For small values
of the ON/OFF ratio, there are many internal states as the elements
switch individually, but these states are closely spaces.  For large values,
conductances are more widely spaced but the system proceeds in avalanches
switching many elements for a small change in the voltage and reducing the
number of accessible states.  Exercising control over the ON/OFF ratio may
thus be a useful way to engineer the desired characteristics into networks
for a particular application.

% If in two-column mode, this environment will change to single-column
% format so that long equations can be displayed. Use
% sparingly.
%\begin{widetext}
% put long equation here
%\end{widetext}

% figures should be put into the text as floats.
% Use the graphics or graphicx packages (distributed with LaTeX2e)
% and the \includegraphics macro defined in those packages.
% See the LaTeX Graphics Companion by Michel Goosens, Sebastian Rahtz,
% and Frank Mittelbach for instance.
%
% Here is an example of the general form of a figure:
% Fill in the caption in the braces of the \caption{} command. Put the label
% that you will use with \ref{} command in the braces of the \label{} command.
% Use the figure* environment if the figure should span across the
% entire page. There is no need to do explicit centering.

% \begin{figure}
% \includegraphics{}%
% \caption{\label{}}
% \end{figure}

% Surround figure environment with turnpage environment for landscape
% figure
% \begin{turnpage}
% \begin{figure}
% \includegraphics{}%
% \caption{\label{}}
% \end{figure}
% \end{turnpage}

% tables should appear as floats within the text
%
% Here is an example of the general form of a table:
% Fill in the caption in the braces of the \caption{} command. Put the label
% that you will use with \ref{} command in the braces of the \label{} command.
% Insert the column specifiers (l, r, c, d, etc.) in the empty braces of the
% \begin{tabular}{} command.
% The ruledtabular enviroment adds doubled rules to table and sets a
% reasonable default table settings.
% Use the table* environment to get a full-width table in two-column
% Add \usepackage{longtable} and the longtable (or longtable*}
% environment for nicely formatted long tables. Or use the the [H]
% placement option to break a long table (with less control than 
% in longtable).
% \begin{table}%[H] add [H] placement to break table across pages
% \caption{\label{}}
% \begin{ruledtabular}
% \begin{tabular}{}
% Lines of table here ending with \\
% \end{tabular}
% \end{ruledtabular}
% \end{table}

% Surround table environment with turnpage environment for landscape
% table
% \begin{turnpage}
% \begin{table}
% \caption{\label{}}
% \begin{ruledtabular}
% \begin{tabular}{}
% \end{tabular}
% \end{ruledtabular}
% \end{table}
% \end{turnpage}

% Specify following sections are appendices. Use \appendix* if there
% only one appendix.
%\appendix
%\section{}

% If you have acknowledgments, this puts in the proper section head.
%\begin{acknowledgments}
% put your acknowledgments here.
%\end{acknowledgments}

% Create the reference section using BibTeX:
\bibliography{/home/forrest/Documents/BibTeX/Advancement_PT_Memnets}
%\bibliography{/home/fsheldon/Documents/BibTeX/Advancement_PT_Memnets}

\end{document}
%
% ****** End of file apstemplate.tex ******

