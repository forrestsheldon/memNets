{
 "metadata": {
  "name": "",
  "signature": "sha256:7f033728821350b31b23cb3ddb2478c98c80f6d263a7402c85c217668af68d65"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Paper Outline"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Summary of the Argument"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Experimental Effect:**  Low voltage pulses give power law distributed residence times in the conductance states of $Ag|Ag_2S|Ag$ atomic switch networks.\n",
      "\n",
      "**Proposed Mechanism:** Pulsing repeatedly probes an area of the switching time distribution that decays as a power law.  This gives a power law residence time distribution.\n",
      "\n",
      "1. Voltage distributions of random resistor networks have a low voltage tail that decays as a power law.  Show that this feature is robust to the concentration $p$ (I believe it strengthens it) and as we relax locality of the network connections\n",
      "\n",
      "2. This gives a long switching time tail that decays as a power law.\n",
      "\n",
      "3. Gaps in this distribution are also power law distributed and give the residence time distribution in the limit of low memory.\n",
      "\n",
      "4. Adding memory maintains the power law but increases the exponent"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Intro"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Challenges in scaling down conventional microelectronics has galvanized interest in new devices and computing architectures\n",
      "\n",
      "* Devices - transistor's power consumption and scaling limits future progress.  Current interest in atomic switches and other memristive systems for passive storage and logic\n",
      "* Architecture - neuromorphic computing aims to mimic the lower power consumption and distributed computation of neural systems where computation is performed directly in memory.  Memristors can function as inorganic synapses.  Most attempts at realizing neuromorphic computation in hardware focus on using conventional techniques such as lithography to create circuits that resemble modern microelectronics.  Neural tissue is highly disordered and naturally balances the cost of wiring with function in its growth.  Until recently, no attempts have been made to develop manufacturing techniques that mimic the complex architecture of neural tissue and observe the consequences when dynamics and memory are involved.\n",
      "\n",
      "Stieg et al. proposed a method utilizing DLA of silver ions in solution to create a complex structure of silver wires.  When exposed to sulphur gas, junctions form in the network which function as $Ag|Ag_2 S|Ag$ atomic switches, capable of transitioning between a high resistance OFF state and a low resistance ON state.  This yields a network of inorganic synapses with a high density of $~10^9$ synapses/cm. When subjected to an external voltage these networks function as enlarged memristors, displaying pinched hysteresis in both weak and strong switching regimes, higher harmonic generation, separate memristive channels and various other behaviors that make them attractive candidates for reservoir computing and other neuromorphic applications.\n",
      "\n",
      "Of particular note is their behavior under pulsed voltage stimulation.  When subjected to low intensity voltage pulses (2V 10ms) with a long duty cycle (10%), the networks make sharp transitions between metastable conductance states.  The distribution of residence times in these conductance states is found to scale as a power law over two orders of magnitude, extending from the pulse width (10ms) to the measurement bandwidth (0.1ms).  This has been attributed to criticality, a phenomenon in which, in the limit of slow driving, a system tunes itself to a state where the size of the response follows a power law distribution, thus giving a singular response function.  In models such as the sand-pile, and in living cultures of neural tissue, the response to external stimulus is an avalanche whose size follows power law distribution.  While the correspondence seems attractive in that in the limit of low voltage driving, atomic switch networks also display a power law, it is marred by two difficulties:  1. While in the case of self organized criticality, the *size* of the response is power law distributed, in atomic switch network, the power law relates to the *time* the systems spends in a conductance state.  Thus, there is not an obvious candidate for a response function that becomes singular in this limit. 2. Theoretical investigations of the networks, including those published by Stieg et al., have found that conductance transitions are likely due to single atomic switches undergoing transitions and not collections undergoing avalanche dynamics.  We have come to a similar conclusion and have thus looked at alternative explanations.\n",
      "\n",
      "We chose to investigate the role of disorder in these networks and whether power law scaling can be explained through the structural properties of the network.  From studies of the random resistor network, it is known that the voltage distribution of these networks is approximately lognormal about the peak with a high voltage tail that quickly decays to $V_{max}$ and a low voltage tail that grows from zero as $V^{b-1}$.  For atomic switches undergoing linear growth, this gives a long switching time tail that decays as $T^{-(b+1)}$.  However, at each switching event in the network, the conductivity changes, so that the residence time distribution is not simply deducible from the switching times. We find, through analytical arguments and simulation, that this is sufficient to give a region of power law scaling in the residence time distribution and demonstrate this for a number of disordered connectivities.  We first investigate in the limit that $\\frac{R_{ON}}{R_{OFF}} \\to 1$ which we term 'no memory' as the network undergoes no conductance changes as a result of it's past dynamics.  We then allow this ratio vary and use simulations to draw conclusions about the effect of memory on the residence time distribution."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Justification of the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to clarify the mechanism that produces the residence time distributions, we first review the properties of atomic switches and our model for them.  Atomic switches are nanoscale, electroionic devices which undergo pinched hysteresis with in their I-V curves with large ratios between their 'ON' and 'OFF' resistance states.  For these networks, we are interested in 'gapless' atomic switches, whose memristive properties derive from the flow of cations within an insulating crystal.  In particular, when subjected to an electric field, insulating $Ag_2 S$ cystals undergo a phase transition to a crystal form with very high diffusivity of silver ions.  These ions drift from the cathode to the anode, where they deposit.  As this deposition process continues, a filament forms through the silver sulfide crystal whose completion corresponds to the transition to the 'ON' conductive state, with the corresponding transition from tunneling to ballistic dispersion in the conducting electrons.  As the nonconducting 'OFF' state is thermodynamically favored, the absence of an electric field leads to the dissolution of the filament and the transition back to the 'OFF' state.  In addition to displaying quantized conductance as more atoms join the conducting filament, atomic switches also display a history dependent decay constant in their return to equilibrium.  Marginally completed filaments will decay quickly, but if more current is run through the junction, allowing the filament to thicken and become stable to thermal fluctuations, the decay constant will become correspondingly longer.  This allows atomic switches to function in both volatile and nonvolatile modes and to mimic the behaviors of organic synapses such as short term and long term potentiation.\n",
      "\n",
      "We model a single atomic switch as a voltage controlled memristor with a state variable $l$, the filament length inside the $Ag_2 S$ crystal and dynamics that give simple linear growth,\n",
      "$$\\frac{dl}{dt} = \\alpha V \\quad l\\in [0, 1].$$\n",
      "Because we only consider current flow in a single direction across the network, and the $Ag|Ag_2 S|Ag$ atomic switches are symmetric devices, we do not need to consider the case of what occurs to the filaments when the current is reversed.  In atomic switches, asymmetry of the filament structure causes breakdown when the current is reversed, allowing them to be switched OFF quickly.  As we only consider conduction in a single direction across the network, the sign of $V$ does not change and we can take the differential equation governing the filament length to be simply $\\frac{dl}{dt} = \\alpha |V|$.  In order to duplicate the sharp transitions between ON and OFF states, we chose a resistance function that makes sharp transitions between these states,\n",
      "$$R(l) = \n",
      "\\begin{cases}\n",
      "R_{OFF} & 0\\leq l < 1 \\\\\n",
      "R_{ON} & l=1\n",
      "\\end{cases}\n",
      "$$\n",
      "While this does not duplicate all of the properties of atomic switches we chose a parsimonious model for clarity's sake.\n",
      "\n",
      "Experimental networks are produced through a growth process in which an area is first seeded with copper posts or microspheres.  These points aggregate silver ions from solution and form a complex mesh of silver wires.  By moderating seed post size, the features of these networks can shift drastically, from fractal dendritic structures to thin, branching wires.  However, despite these drastic shifts in structure, it is found that the power law residence time distribution is robust to these morphological changes in the network.  We thus expect to have some freedom in choosing the networks structure, and that the salient features causing the power law will be common to many disordered networks.  Also, despite a wide range of scales in the wires created by the growth process, IR imagings shows distributed Joule heating throughout the network, indicating that the network is not dominated by the conduction of a few long wires.  The typical length of connections must then be much less than the linear size of the network.  With these allowances and constraints in mind, we choose to model the network as a random square lattice with bond concentration $p$.  The conductivity properties of these networks are well studied and of particular interest is the voltage distribution at percolation, which diplays power law scaling at low voltages.  We show that this effect is robust across a wide range of concentrations $p$ and that a similar distribution holds as we relax the locality of the random square lattice.  In fact, the tail at low voltages becomes stronger as $p$ increases as more bonds are involved in 'blobs' where the current is widely distributed.\n",
      "\n",
      "FIGURES DEMONSTRATING THIS"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Modeling Dynamics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the limit of low memory, $\\frac{R_{ON}}{R_{OFF}}\\to 1$, the switching times throughout the network are determined by the initial voltage distribution.  This is because transitions from $R_{OFF} \\to R_{ON}$ do not alter the network conductivity and thus do not change the current.  A random network at bond concentration $p$ is thus generated and switching times are calculated directly as taking $\\alpha=1$), $T = \\frac{1}{V}$.  These are then sorted and the residence times are calculated as the differences between successive switching times.  This yields the distribution\n",
      "\n",
      "FIGURE\n",
      "\n",
      "\n",
      "When memory is added, $\\frac{R_{ON}}{R_{OFF}} = \\beta$, we must perform some integration.  For the simple model we have adopted, this may be undertaken exactly.  A network is generated and the voltages across the network are solved for.  The switching time for all bonds is calculated as $t = \\frac{L - l_{ij}}{V_{ij}}$ and the shortest time in the network, $t^*$ is found.  The corresponding switch is set to $R_{ON}$ and the lengths of all filaments in the network are updated to $l_{ij} \\to l_{ij} + t^*  V_{ij}$.  The differences between switching times, $t^*$ are accumulated as the residence time distribution.  The voltages are then solved for again and the process repeated.  This has been repeated for several values of the memory parameter $\\beta$ and are displayed in Figure\n",
      "\n",
      "Figure displaying the residence time distributions for various values of $\\beta$.\n",
      "\n",
      "A remark on a few salient features of the distributions.  First, near the peak, the voltage distributions of the random resistor network are approximately lognormal.  The transformation $T = \\frac{L}{V}$ maps a lognormal distribution with a $\\mu$ parameter $\\ln\\nu$ to another with a $\\mu$ parameter $\\ln \\frac{L}{\\nu}$. The peak is thus transferred to the distribution of switching times.  The low voltage power law in the voltage distribution becomes a power law tail in the long switching times that decays as\n",
      "$T^{-(b+1)}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "From Switching time to Residence Time"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the limit of low memory, we can relate the switching time distribution to the residence time distribution through an analytical argument by which we show that a power law tail in the switching time distribution suggests a power law tail in the residence time distribution.  To show this we aim to obtain the distribution of intervals in a sample of $p(t)$. The joint distribution of order statistics in a sample of size $n$ is, for the $i$th and $j$th elements,\n",
      "$$ f_{X_i, X_j} (x, y) = \\frac{n!}{(i-1)!(j - 1 - i)! (n - j)!}F(x)^{i-1} f(x)[F(y) - F(x)]^{j-1-i}f(y)[1-F(y)]^{n-j}$$\n",
      "where $f(x)$ is the probability density function and $F(x)$ is the cummulative distribution function. (To obtain this, begin with the full order statistic distribution $n!\\prod_{i=1}^n f(x_i)$ and integrate out the variables you don't care about, using much induction.)\n",
      "This gives the probability density that in an ordered sample, the $i$th element is equal to $x$ and the $j$th element is equal to $y$.  For $j = i+1$ this is,\n",
      "$$ f_{X_i, X_{i+1}} (x, y) = \\frac{n!}{(i-1)!(n - (i+1))!}F(x)^{i-1} f(x)f(y)[1-F(y)]^{n-(i+1)}$$\n",
      "To obtain the distribution for the $i$th interval to be size $v$ we subsitute $y = x + v$ and integrate over $x$,\n",
      "$$p_i(v) = \\frac{n!}{(i-1)!(n - (i+1))!}\\int_{x_{min}}^\\infty dx\\,F(x)^{i-1} f(x)f(x + v)[1-F(x + v)]^{n-(i+1)}.$$\n",
      "Finally, to obtain the probability that any interval is of size $v$ we sum over $i$ from 1 to $n-1$ (normalizing also by $\\frac{1}{n-1}$),\n",
      "$$p(v) = \\frac{1}{n-1}\\sum_{i=1}^{n-1} \\frac{n!}{(i-1)!(n - (i+1))!}\\int_{x_{min}}^\\infty dx\\, F(x)^{i-1} f(x)f(x + v)[1-F(x + v)]^{n-(i+1)}$$\n",
      "Shifting the indices of our sum, we recognize it at a binomial expansion,\n",
      "$$p(v) = n\\int_{x_{min}}^\\infty dx\\,\\sum_{k=0}^{n-2} \\frac{(n-2)!}{k!((n -2) - k)!} F(x)^{k} f(x)f(x + v)[1-F(x + v)]^{((n-2)-k)}$$\n",
      "which we can evaluate giving,\n",
      "$$p(v) = n\\int_{x_{min}}^\\infty dx\\, (1 - (F(v+x) - F(x)))^{n-2}f(x)f(v+x).$$\n",
      "\n",
      "**Here**, I am working on an argument that shows that power law switching distributions should give power law residence distributions.  For large N, the peak of the distibution should be densely populated with samples and so long gaps in the distribution should come from the tails.  Power law distributions satisfy properties like, $\\frac{P(x>X+Y)}{P(x>\\max(X, Y))} \\to 1 \\quad x\\to\\infty$ which is almost saying that algebraic combinations of variables should be dominated by the largest value and thus be on the same order which should cause the distributions to be similar."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Adding Memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}